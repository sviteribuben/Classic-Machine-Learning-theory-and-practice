{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "name": "jun_ml_linear_regression_II_les_1 + HW_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sviteribuben/ML_01/blob/main/jun_ml_linear_regression_II_les_1_%2B_HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKJGB4sCiWzr"
      },
      "source": [
        "В прошлом уроке мы узнали, как обучить и применить модель линейной регрессии, а так же как измерить качество модели. В этом уроке поговорим, как улучшить этот простой алгоритм и сделать обучение более эффективным. Мы познакомимся с понятиями \"регуляризация\" и \"градиентный спуск\".\n",
        "\n",
        "Вы сможете обучать линейную регрессию, не \"упираясь\" в аппаратные ресурсы, а так же узнаете, как увеличить качество решения с помощью механизма регуляризации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjRhay_4iWzs"
      },
      "source": [
        "# Урок 1. Регуляризация\n",
        "\n",
        "Регуляризация - это способ борьбы с таким явлением как \"переобучение\".\n",
        "\n",
        "**Что такое переобучение?** Переобучение (англ. *overfitting*, буквально - \"переподгонка\") - негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для применения алгоритма к дополнительным данным или будущим наблюдениям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qvDUDUQiWzt"
      },
      "source": [
        "Пример оверфиттинга проще всего привести в виде картинки. Пусть вы решаете задачу классификации на два класса ( о которой уже знаете с первых уроков этого курса)\n",
        "* сначала модель, которая обучена не совсем хорошо (underfit) - разделяющая линия прямая и много \"красных\" точек неправильно классифицированы\n",
        "* затем хорошо обученная модель (normal) - есть какой-то баланс\n",
        "* переобученная модель (overfit) - разделяющая линия слишком сильно \"облизывает\" обучающие данные.\n",
        " \n",
        "![overfit_example](https://248006.selcdn.ru/public/Data-science-3/img/overfit_example.png)\n",
        "\n",
        "Чем же плохо переобучение? Когда в модель придут \"новые\" точки, то качество модели будет низким, потому что модель слишком сильно подогналась под обучающие данные. В этом случае говорят, что падает \"обобщающая способность\" - модель не получается обощить на новые данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA8rAxXCiWzu"
      },
      "source": [
        "**Почему происходит переобучение?** Всё дело в алгоритме подбора параметров модели. В модуле \"Линейная регрессия. Часть I\" в домашнем задании по уроку \"Полиномиальная регрессия\" нужно было подобрать такой параметр, как \"степень полинома\". Напомним общий алгоритм выбора *наилучшей степени полинома*:\n",
        "\n",
        "\n",
        "1. возьмите все степени от 1 до 10 по порядку, без пропусков\n",
        "1. для каждой степени полинома: обучите полиномиальную регрессию, сделайте предсказания и вычислите метрику качества (например, r2-score)\n",
        "1. найдите степень полинома, при которой у модели будет лучший r2-score\n",
        "\n",
        "Вспомним, что эта процедура называется *Grid Search* и помогает найти лучшие параметры для модели методом перебора.\n",
        "\n",
        "Вот тут-то и поджидает нас переобучение! Мы выберем модель, которая даёт лучший скор на обучающих данных. А вот когда в модель придут новые данные, то качество может быть сильно хуже"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpCOgxlFiWzu"
      },
      "source": [
        "**Как детектировать переобучение?** Перед нами стоит вопрос, как выбрать правильные пераметры модели, чтобы она не \"оверфитнулась\". Есть простой алгоритм, который называется \"контроль на отложенной (валидационной) выборке\". Тренировку модели из пункта (2) алгоритма *GridSearch* придётся немного усложнить:\n",
        "\n",
        "* разбиваем обучающую выборку на две части: в одной части 80% обучающих примеров (эта часть называется *train set*), в другой части 20% обучающих примеров (эта часть называется *validation set*)\n",
        "* выбираем метрику качества  модели (для регрессии, например, MSE)\n",
        "* обучаем модель на тренировочном наборе данных\n",
        "* делаем предсказания на валидационном наборе данных и вычисляем метрику качества\n",
        "\n",
        "**Признак переобучения**: Если качество на валидации сильно хуже, чем качество на обучающем сете - всё плохо, модель переобучилась. Запомните этот признак, скоро мы его применим на практике. Такую модель нельзя использовать, с переобучением надо бороться!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_J31zceiWzv"
      },
      "source": [
        "**Как бороться с переобучением линейной регрессии?** Нам надо как-то \"наказать\" модель за то, что она слишком сильно подгоняется под обучающую выборку. Это можно сделать помощью регуляризации! Регуляризация - это специальная модификация модели линейной регрессии. В стандартной библиотеки sklearn есть два класса, в которых реализована регуляризация:\n",
        "* sklearn.linear_model.Ridge, ссылка на доку https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "* sklearn.linear_model.Lasso, ссылка на доку https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "\n",
        "Чем отличаются эти два класса мы узнаем в следующих уроках этого модуля. Мы уже знакомы с классом `sklearn.linear_model.LinearRegression`, с который вообще не требует никаких параметров при создании, а вот классы `Ridge` и `Lasso` принимают на вход т.н. параметр регуляризации *alpha*, который принимает значения от $0$ до $1$ - чем ближе к единице, тем регуляризация сильнее, тем сильнее наказываем модель за сильную \"подгонку\" под обучающие данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxd8yfwFiWzw"
      },
      "source": [
        "В следующем уроке мы  продемонстрируем, как переобучается полиномиальная регрессия, а так же попытаемся победить этот эффект с помощью регуляризации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_NfjnxXzhTz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFAkzi6gbUok"
      },
      "source": [
        "# Урок 2. Переобучение на примере линейной регрессии\n",
        "\n",
        "\n",
        "Давайте проведём эксперимент и увидим на примере, как переобучается линейная регрессия. Для начала загрузим датасет из csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KZgT0pYDc79",
        "outputId": "47e6f2be-e2ca-4e6c-a52f-ab44c8a89ed5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmR4-VXdbUon",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8cae75a2-2579-48ed-9591-9e9faf66bb77"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML_01/3.10_non_linear.csv', sep=',')\n",
        "data.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_train</th>\n",
              "      <th>y_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.138368</td>\n",
              "      <td>0.838812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.157237</td>\n",
              "      <td>0.889313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.188684</td>\n",
              "      <td>1.430040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.685553</td>\n",
              "      <td>1.717309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.874237</td>\n",
              "      <td>2.032588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    x_train   y_train\n",
              "0  0.138368  0.838812\n",
              "1  0.157237  0.889313\n",
              "2  0.188684  1.430040\n",
              "3  0.685553  1.717309\n",
              "4  0.874237  2.032588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpnRYhULbUo0"
      },
      "source": [
        "Тренироваться будем на полиномиальной регрессии, потому что она сильно склонна к переобучению и мы уже знакомы с этой моделью. Сгенерируем полиномиальные признаки так же, как вы уже делали в модуле \"Линейная регрессия. Часть I\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kgr-BdKbUo1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def generate_degrees(source_data: list, degree: int):\n",
        "    \"\"\"Функция, которая принимает на вход одномерный массив, а возвращает n-мерный\n",
        "    Для каждой степени от 1 до  degree возводим x в эту степень\n",
        "    \"\"\"\n",
        "    return np.array([\n",
        "          source_data**n for n in range(1, degree + 1)  \n",
        "    ]).T"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHkNCITTbUo9"
      },
      "source": [
        "Обучаем модель на валидации, проверяем на контроле для степени полинома *degree=8*. Для разбиения мы воспользуемся функцией train_test_split (ссылка на доку: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Функция принимает следующие аргументы:\n",
        "\n",
        "* $X$ и $y$ - массивы, которые хотим расщепить на валидацию и контроль\n",
        "* *test_size* принимает значения от нуля до единицы и означает долю объектов, которые нужно отложить на валидацию (обычно выбирают значения между $0.15$ и $0.35$)\n",
        "* *random_state* - любое целое число. Функция разбивает выборку случайным образом, но если вы задали параметр random_state, то разбиение не будет меняться в разных запусках программы. Это нужно для воспроизводимости исследований и является признаком хорошего тона в программировании."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZb-WArNbUo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db252f37-6d6a-429d-bc8a-075cc533a39e"
      },
      "source": [
        "degree = 8\n",
        "X = generate_degrees(data['x_train'], degree)\n",
        "y = data.y_train.values\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "model = Ridge(alpha=0).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(f\"Качество на валидации: {mean_squared_error(y_valid, y_pred).round(3)}\")\n",
        "print(f\"Качество на обучении: {mean_squared_error(y_train, y_pred_train).round(3)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Качество на валидации: 0.119\n",
            "Качество на обучении: 0.052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.97797e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jhYpis6bUpG"
      },
      "source": [
        "Теперь обучим полиномиальную регрессию для степени *degree = 12* c параметром регуляризации *alpha=0*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYzdr4rIbUpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19a4808-2920-445a-822b-01b9497192f7"
      },
      "source": [
        "degree = 12\n",
        "X = generate_degrees(data['x_train'], degree)\n",
        "y = data.y_train.values\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "model = Ridge(alpha=0).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(f\"Качество на валидации: {mean_squared_error(y_valid, y_pred).round(3)}\")\n",
        "print(f\"Качество на обучении: {mean_squared_error(y_train, y_pred_train).round(3)}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Качество на валидации: 0.125\n",
            "Качество на обучении: 0.051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnCmofQwbUpQ"
      },
      "source": [
        "Как изменилась ошибка на обучении? Было $0.052$, стало $0.051$, т.е. *ошибка на обучении падает*.\n",
        "\n",
        "Как изменилась ошибка на валидации? Было $0.119$, стало $0.125$, т.е. *ошибка на валидации растёт*.\n",
        "\n",
        "Это же верный **признак переобучения**! Ошибка на валидации растёт, а на обучении падает. Степень полинома $n=12$ хуже, чем степень полинома $n=8$, модель переобучилась. Это печально, как же нам победить переобучение?\n",
        "\n",
        "**Практическое задание**: предлагаю вам победить переобучение самостоятельно! Обучите *Ridge* регрессию с параметром регуляризации $\\alpha=0.01$. \n",
        "\n",
        "Как изменилась ошибка на обучении? Как изменилась ошибка на валидации? Удалось ли победить переобучение?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXnFc3vubUpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd20c9b-8c19-4781-d8fd-b13cf890815a"
      },
      "source": [
        "# -- ВАШ КОД ТУТ --\n",
        "degree = 8\n",
        "X = generate_degrees(data['x_train'], degree)\n",
        "y = data.y_train.values\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "model = Ridge(alpha=0.01, normalize=True).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(f\"Качество на валидации: {mean_squared_error(y_valid, y_pred).round(4)}\")\n",
        "print(f\"Качество на обучении: {mean_squared_error(y_train, y_pred_train).round(4)}\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Качество на валидации: 0.0867\n",
            "Качество на обучении: 0.1513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3krnaGwF6cr",
        "outputId": "f59a723b-0773-427e-be30-8b44ca066985"
      },
      "source": [
        "degree = 12\n",
        "X = generate_degrees(data['x_train'], degree)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "model = Ridge(alpha=0.01, normalize=True).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(f\"Качество на валидации: {mean_squared_error(y_valid, y_pred).round(4)}\")\n",
        "print(f\"Качество на обучении: {mean_squared_error(y_train, y_pred_train).round(4)}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Качество на валидации: 0.0847\n",
            "Качество на обучении: 0.1456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aLceU3IJBoi"
      },
      "source": [
        "если использовать нормализацию то все отрабатывает как надо! Как изменилась ошибка на обучении? Было  0.1513, стало  0.1456, т.е. ошибка на обучении падает.\n",
        "Как изменилась ошибка на валидации? Было  0.0867, стало  0.0847, т.е. ошибка на валидации также снижается!\n",
        "Переобучение **нивилировано** с изменением параметра $\\alpha=0.01$ и \"включением\" нормализации! Ошибка на валидации падает, а на обучении падает алсо! \n",
        "Степень полинома  n=12  хуже, чем степень полинома  n=8 , модель годная! Пулим в прод))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV8uvarGbUpY"
      },
      "source": [
        "Я надеюсь, что переобучение с помощью регуляризации победить вам удалось!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYfUg72kbUpa"
      },
      "source": [
        "Чему полезному мы научились?\n",
        "\n",
        "* узнали, что такое переобучение\n",
        "* научились детектировать его с помощью валидационной выборки\n",
        "* смогли победить переобучение с помощью библиотечного класса Ridge"
      ]
    }
  ]
}